{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Oe-frv1E5_kTZbalZWCjOvFtLjigpr39","timestamp":1703056256941}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82_IDwwCsduT","executionInfo":{"status":"ok","timestamp":1706757846210,"user_tz":-420,"elapsed":2764,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}},"outputId":"f6e429e2-c0a5-47a3-db98-7a75bb98df01"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bQh5rmWf2U7_","executionInfo":{"status":"ok","timestamp":1706758417635,"user_tz":-420,"elapsed":887,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"outputs":[],"source":["import random\n","\n","random.seed(0)\n","\n","PUNCTUATIONS = ['.', ',', '!', '?', ';', ':']\n","DATASETS = ['18. AEDA']\n","NUM_AUGS = [8]\n","PUNC_RATIO = 0.3\n","\n","# Insert punction words into a given sentence with the given ratio \"punc_ratio\"\n","def insert_punctuation_marks(sentence, punc_ratio=PUNC_RATIO):\n","\twords = sentence.split(' ')\n","\tnew_line = []\n","\tq = random.randint(1, int(punc_ratio * len(words) + 1))\n","\tqs = random.sample(range(0, len(words)), q)\n","\n","\tfor j, word in enumerate(words):\n","\t\tif j in qs:\n","\t\t\tnew_line.append(PUNCTUATIONS[random.randint(0, len(PUNCTUATIONS)-1)])\n","\t\t\tnew_line.append(word)\n","\t\telse:\n","\t\t\tnew_line.append(word)\n","\tnew_line = ' '.join(new_line)\n","\treturn new_line\n","\n","\n","def main(dataset):\n","\tfor aug in NUM_AUGS:\n","\t\tdata_aug = []\n","\t\twith open(dataset + '/train_negatif.txt', 'r') as train_orig:\n","\t\t\tfor line in train_orig:\n","\t\t\t\tline1 = line.split('\\t')\n","\t\t\t\tlabel = line1[0]\n","\t\t\t\tsentence = line1[1]\n","\t\t\t\tfor i in range(aug):\n","\t\t\t\t\tsentence_aug = insert_punctuation_marks(sentence)\n","\t\t\t\t\tline_aug = '\\t'.join([label, sentence_aug])\n","\t\t\t\t\tdata_aug.append(line_aug)\n","\t\t\t\tdata_aug.append(line)\n","\n","\t\twith open(dataset + '/train_orig_plus_augs_' + str(aug) + '.txt', 'w') as train_orig_plus_augs:\n","\t\t\ttrain_orig_plus_augs.writelines(data_aug)\n","\n","gdrive_folder = '/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/1. experiment 2/'\n","for dataset in DATASETS:\n","  main(gdrive_folder + dataset)"]}]}