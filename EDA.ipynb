{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/aflah02/Easy-Data-Augmentation-Implementation/blob/main/EDA.ipynb","timestamp":1701245417196}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","from nltk.corpus import wordnet\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import EarlyStopping\n","import pickle\n","\n","def plot_graphs(history, metric):\n","  plt.plot(history.history[metric])\n","  plt.plot(history.history['val_'+metric], '')\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(metric)\n","  plt.legend([metric, 'val_'+metric])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-LuYDsQtSDk","outputId":"fa610303-20ce-4985-ec40-eaf0946ebf8b","executionInfo":{"status":"ok","timestamp":1706768038978,"user_tz":-420,"elapsed":12,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","execution_count":58,"metadata":{"id":"r3iSEz0crpcJ","executionInfo":{"status":"ok","timestamp":1706768039347,"user_tz":-420,"elapsed":20,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"outputs":[],"source":["def eda_SR(originalSentence, n):\n","  \"\"\"\n","  Paper Methodology -> Randomly choose n words from the sentence that are not stop words.\n","                       Replace each of these words with one of its synonyms chosen at random.\n","  originalSentence -> The sentence on which EDA is to be applied\n","  n -> The number of words to be chosen for random synonym replacement\n","  \"\"\"\n","  stops = set(stopwords.words('indonesian'))\n","  splitSentence = list(originalSentence.split(\" \"))\n","  splitSentenceCopy = splitSentence.copy()\n","  # Since We Make Changes to The Original Sentence List The Indexes Change and Hence an initial copy proves useful to get values\n","  ls_nonStopWordIndexes = []\n","  for i in range(len(splitSentence)):\n","    if splitSentence[i].lower() not in stops:\n","      ls_nonStopWordIndexes.append(i)\n","  if (n > len(ls_nonStopWordIndexes)):\n","    raise Exception(\"The number of replacements exceeds the number of non stop word words\")\n","  for i in range(n):\n","    indexChosen = random.choice(ls_nonStopWordIndexes)\n","    ls_nonStopWordIndexes.remove(indexChosen)\n","    synonyms = []\n","    originalWord = splitSentenceCopy[indexChosen]\n","    for synset in wordnet.synsets(originalWord):\n","      for lemma in synset.lemmas():\n","        if lemma.name() != originalWord:\n","          synonyms.append(lemma.name())\n","    if (synonyms == []):\n","      continue\n","    splitSentence[indexChosen] = random.choice(synonyms).replace('_', ' ')\n","  return \" \".join(splitSentence)"]},{"cell_type":"code","source":["print(eda_SR(\"halo admin untuk besok stock vaksin moderna ada ga ya estimasi dimana terimakasih\", 6))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9S1DukZer1Am","outputId":"f32b6b07-3464-4975-dffe-4ebb93b90917","executionInfo":{"status":"ok","timestamp":1706768039347,"user_tz":-420,"elapsed":18,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["annulus admin untuk besok ancestry vaksin moderna ada Ga ya estimasi dimana terimakasih\n"]}]},{"cell_type":"code","source":["def eda_RI(originalSentence, n):\n","  \"\"\"\n","  Paper Methodology -> Find a random synonym of a random word in the sentence that is not a stop word.\n","                       Insert that synonym into a random position in the sentence. Do this n times\n","  originalSentence -> The sentence on which EDA is to be applied\n","  n -> The number of times the process has to be repeated\n","  \"\"\"\n","  stops = set(stopwords.words('indonesian'))\n","  splitSentence = list(originalSentence.split(\" \"))\n","  splitSentenceCopy = splitSentence.copy()\n","  # Since We Make Changes to The Original Sentence List The Indexes Change and Hence an initial copy proves useful to get values\n","  ls_nonStopWordIndexes = []\n","  for i in range(len(splitSentence)):\n","    if splitSentence[i].lower() not in stops:\n","      ls_nonStopWordIndexes.append(i)\n","  if (n > len(ls_nonStopWordIndexes)):\n","    raise Exception(\"The number of replacements exceeds the number of non stop word words\")\n","  WordCount = len(splitSentence)\n","  for i in range(n):\n","    indexChosen = random.choice(ls_nonStopWordIndexes)\n","    ls_nonStopWordIndexes.remove(indexChosen)\n","    synonyms = []\n","    originalWord = splitSentenceCopy[indexChosen]\n","    for synset in wordnet.synsets(originalWord):\n","      for lemma in synset.lemmas():\n","        if lemma.name() != originalWord:\n","          synonyms.append(lemma.name())\n","    if (synonyms == []):\n","      continue\n","    splitSentence.insert(random.randint(0,WordCount-1), random.choice(synonyms).replace('_', ' '))\n","  return \" \".join(splitSentence)"],"metadata":{"id":"ki7HhW0LuK32","executionInfo":{"status":"ok","timestamp":1706768039347,"user_tz":-420,"elapsed":16,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["print(eda_RI(\"halo admin untuk besok stock vaksin moderna ada ga ya estimasi dimana terimakasih\", 6))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqWbchb_uS6-","outputId":"20bac182-50e4-4031-c567-1eab0fb3948c","executionInfo":{"status":"ok","timestamp":1706768039347,"user_tz":-420,"elapsed":14,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["halo aureole admin untuk besok stock Peach State vaksin moderna ada ga ya estimasi dimana terimakasih\n"]}]},{"cell_type":"code","source":["def eda_RS(originalSentence, n):\n","  \"\"\"\n","  Paper Methodology -> Find a random synonym of a random word in the sentence that is not a stop word.\n","                       Insert that synonym into a random position in the sentence. Do this n times\n","  originalSentence -> The sentence on which EDA is to be applied\n","  n -> The number of times the process has to be repeated\n","  \"\"\"\n","  splitSentence = list(originalSentence.split(\" \"))\n","  WordCount = len(splitSentence)\n","  for i in range(n):\n","    firstIndex = random.randint(0,WordCount-1)\n","    secondIndex = random.randint(0,WordCount-1)\n","    while (secondIndex == firstIndex and WordCount != 1):\n","      secondIndex = random.randint(0,WordCount-1)\n","    splitSentence[firstIndex], splitSentence[secondIndex] = splitSentence[secondIndex], splitSentence[firstIndex]\n","  return \" \".join(splitSentence)"],"metadata":{"id":"vNxMDuWEyGWw","executionInfo":{"status":"ok","timestamp":1706768039348,"user_tz":-420,"elapsed":12,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["print(eda_RS(\"ceo moderna sebut efektivitas CEO vaksin covid mungkin akan turun melawan varian omicron\", 6))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZSJVxXjK1XLD","outputId":"60cbd170-0103-4225-ba88-5666bc0d6ecb","executionInfo":{"status":"ok","timestamp":1706768039349,"user_tz":-420,"elapsed":12,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["omicron covid efektivitas sebut ceo mungkin vaksin moderna akan turun melawan varian CEO\n"]}]},{"cell_type":"code","source":["def eda_RD(originalSentence, p):\n","  \"\"\"\n","  Paper Methodology -> Randomly remove each word in the sentence with probability p.\n","  originalSentence -> The sentence on which EDA is to be applied\n","  p -> Probability of a Word Being Removed\n","  \"\"\"\n","  og = originalSentence\n","  if (p == 1):\n","      raise Exception(\"Always an Empty String Will Be Returned\")\n","  if (p > 1 or p < 0):\n","    raise Exception(\"Improper Probability Value\")\n","  splitSentence = list(originalSentence.split(\" \"))\n","  lsIndexesRemoved = []\n","  WordCount = len(splitSentence)\n","  for i in range(WordCount):\n","    randomDraw = random.random()\n","    if randomDraw <= p:\n","      lsIndexesRemoved.append(i)\n","  lsRetainingWords = []\n","  for i in range(len(splitSentence)):\n","    if i not in lsIndexesRemoved:\n","      lsRetainingWords.append(splitSentence[i])\n","  if (lsRetainingWords == []):\n","    return og\n","  return \" \".join(lsRetainingWords)"],"metadata":{"id":"J7Ftz9dw1aU7","executionInfo":{"status":"ok","timestamp":1706768039817,"user_tz":-420,"elapsed":477,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["print(eda_RD(\"selanjutnya kita bisa menghitung jumlah kemunculan tiap kata pada text\", 0.3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3BexJBe3GiU","outputId":"eb249ba2-3703-446d-b3e7-2ead1059a4a3","executionInfo":{"status":"ok","timestamp":1706768039819,"user_tz":-420,"elapsed":25,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["selanjutnya kita bisa menghitung jumlah kemunculan tiap pada\n"]}]},{"cell_type":"code","source":["print(eda_RD(\"selanjutnya kita bisa menghitung jumlah kemunculan tiap kata pada text\", 0.7))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaHxFcpzQ_Ow","executionInfo":{"status":"ok","timestamp":1706768039821,"user_tz":-420,"elapsed":23,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}},"outputId":"ce523225-74ce-4139-d574-8d7287b2cdbc"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["selanjutnya bisa menghitung jumlah tiap kata pada\n"]}]},{"cell_type":"markdown","source":["### Building Dataset"],"metadata":{"id":"WJ7lKLxQX1Y7"}},{"cell_type":"code","source":["# !wget -q https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/train.tsv\n","# !wget -q https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/test.tsv\n","# !wget -q https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/dev.tsv"],"metadata":{"id":"CxBtup4GaBfU","executionInfo":{"status":"ok","timestamp":1706768039822,"user_tz":-420,"elapsed":18,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c34mYUoRGEhK","executionInfo":{"status":"ok","timestamp":1706768039823,"user_tz":-420,"elapsed":18,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Lz5QhQIGFzn","executionInfo":{"status":"ok","timestamp":1706768043158,"user_tz":-420,"elapsed":3352,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}},"outputId":"e38fe2ae-79b8-466c-cfef-dbd89ebc002b"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# import pandas as pd\n","# from sklearn.model_selection import train_test_split\n","\n","# # Load the dataset from a CSV file\n","# data = pd.read_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/tweet_clean.xlsx')  # Replace 'your_dataset.csv' with your dataset file\n","\n","# # Split the dataset into train and test sets (80% train, 20% test)\n","# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# # Save the train and test data into separate CSV files\n","# train_data.to_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/train_data.xlsx', index=False)\n","# test_data.to_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/test_data.xlsx', index=False)\n"],"metadata":{"id":"lgL7VKonjvdI","executionInfo":{"status":"ok","timestamp":1706768043159,"user_tz":-420,"elapsed":16,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","import numpy as np"],"metadata":{"id":"fxND2f8NVczO","executionInfo":{"status":"ok","timestamp":1706768043159,"user_tz":-420,"elapsed":14,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["def buildTrainTestDatasets(doAug, AugTechs, alpha, NumberOfTrainingSamplesTouse, n_aug):\n","  df_train = pd.read_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/1. experiment 2/1. Dataset/train_negatif.xlsx',  names = ['label','text'])\n","  #df_dev = pd.read_csv('dev.tsv', delimiter = '\\t', names = ['Sentence', 'Label'])\n","  df_test = pd.read_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/1. experiment 2/1. Dataset/test_data.xlsx',  names = ['label','text'])\n","  df_train = df_train[df_train['label'] == 1]\n","\n","  # print(len(df_train))\n","  # print(df_train.head())\n","  # print(len(df_test))\n","  # print(df_test.head())\n","\n","  #df_train = pd.concat([df_train, df_dev])\n","  df_train = df_train.reset_index(drop=True)\n","  df_train = df_train.loc[:, [\"label\", \"text\"]]\n","  if (NumberOfTrainingSamplesTouse > len(df_train)):\n","    raise Exception(\"More Samples Asked For Than Present\")\n","\n","  df_train = df_train.iloc[:NumberOfTrainingSamplesTouse]\n","\n","  if (doAug):\n","    if (AugTechs == None):\n","      AugTechs = ['SR', 'RI', 'RD', 'RS']\n","    ls_train_labels = df_train['label'].to_list()\n","    ls_train_sentences = df_train['text'].to_list()\n","    ls_train_aug_method = list(np.zeros(len(df_train)))\n","\n","    # print(\"ls_train_sentences:\", ls_train_sentences)\n","\n","    count = len(ls_train_sentences)\n","    for i in tqdm(range(count)):\n","      for iter in range(n_aug):\n","        ls_train_labels.append(ls_train_labels[i])\n","        techniqueChosen = random.choice(AugTechs)\n","        ls_train_aug_method.append(techniqueChosen)\n","        # print(\"ls_train_sentences\", i, \":\", ls_train_sentences[i])\n","        # print(\"len\", len(ls_train_sentences))\n","        if (techniqueChosen == 'SR'):\n","          ls_train_sentences.append(eda_SR(ls_train_sentences[i], int(len(ls_train_sentences[i])*alpha)))\n","        elif (techniqueChosen == 'RI'):\n","          ls_train_sentences.append(eda_RI(ls_train_sentences[i], int(len(ls_train_sentences[i])*alpha)))\n","        elif (techniqueChosen == 'RS'):\n","          ls_train_sentences.append(eda_RS(ls_train_sentences[i], int(len(ls_train_sentences[i])*alpha)))\n","        elif (techniqueChosen == 'RD'):\n","          ls_train_sentences.append(eda_RD(ls_train_sentences[i], alpha))\n","    df_train = pd.DataFrame(\n","    {'label': ls_train_labels,\n","     'text': ls_train_sentences,\n","    })\n","\n","  df_train_aug = pd.DataFrame(\n","      {\n","          'label': ls_train_labels,\n","          'method': ls_train_aug_method,\n","          'text': ls_train_sentences\n","      }\n","  )\n","\n","  target_train = df_train.pop('label')\n","  target_test = df_test.pop('label')\n","  feature_names = ['text']\n","  train_features = df_train[feature_names]\n","  test_features = df_test[feature_names]\n","  train_dataset = tf.convert_to_tensor(train_features)\n","  test_dataset = tf.convert_to_tensor(test_features)\n","  return train_dataset, target_train, test_dataset, target_test, df_train_aug"],"metadata":{"id":"eOqxgdLi9vNU","executionInfo":{"status":"ok","timestamp":1706768043159,"user_tz":-420,"elapsed":13,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["  df_train = pd.read_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/1. experiment 2/1. Dataset/train_negatif.xlsx',  names = ['label','text'])\n","  df_train = df_train[df_train['label'] == -1]\n","  df_train.to_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/1. experiment 2/1. Dataset/train_eda_negatif.xlsx')\n","  # print(len(df_train))\n","  # #df_dev = pd.read_csv('dev.tsv', delimiter = '\\t', names = ['Sentence', 'Label'])\n","  # df_test = pd.read_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/test_data.xlsx',  names = ['label','text'])\n"],"metadata":{"id":"4kLevoz9Z4JW","executionInfo":{"status":"ok","timestamp":1706768043676,"user_tz":-420,"elapsed":527,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["## Total Tweet\n","### =Train Data=\n","#### netral = 6082\n","#### positif = 1299\n","#### negatif = 900\n","\n","### =Test Data=\n","#### netral = 1360\n","#### positif = 490\n","#### negatif = 347"],"metadata":{"id":"5jhvy0h0n52p"}},{"cell_type":"code","source":["train_aug_dataset, target_aug_train, test_aug_dataset, target_aug_test, df_train_aug = buildTrainTestDatasets(True, None, 0.04, 500, 7)\n","# train_aug_dataset, target_aug_train, test_aug_dataset, target_aug_test = buildTrainTestDatasets(True, \"RD\", 0.05, 500, 16)\n","print(f\"jumlah train aug dataset: {len(train_aug_dataset)}\")\n","print(train_aug_dataset[:5])\n","# print(len(train_aug_method))\n","# print(len(train_aug_dataset))\n","\n","print(df_train_aug.head())\n","\n","df_train_aug.to_excel('/content/drive/MyDrive/Thesis - Sentiment Analysis Dataset/1. experiment 2/1. Dataset/train_eda_negatif.xlsx')\n","\n","# stopp\n","\n","# train_aug_dataset = tf.squeeze(train_aug_dataset)\n","# test_aug_dataset = tf.squeeze(test_aug_dataset)\n","# target_aug_train = tf.squeeze(target_aug_train)\n","# target_aug_test = tf.squeeze(target_aug_test)"],"metadata":{"id":"Dt-Dp6kQ-r7_","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1706768044628,"user_tz":-420,"elapsed":958,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}},"outputId":"621391ab-8faa-4a5b-cd99-4529864708a5"},"execution_count":73,"outputs":[{"output_type":"error","ename":"Exception","evalue":"More Samples Asked For Than Present","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-73-c0d1d69e42ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_aug_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_aug_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_aug_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_aug_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildTrainTestDatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# train_aug_dataset, target_aug_train, test_aug_dataset, target_aug_test = buildTrainTestDatasets(True, \"RD\", 0.05, 500, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"jumlah train aug dataset: {len(train_aug_dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_aug_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(len(train_aug_method))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-71-76a0ee40bbbe>\u001b[0m in \u001b[0;36mbuildTrainTestDatasets\u001b[0;34m(doAug, AugTechs, alpha, NumberOfTrainingSamplesTouse, n_aug)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNumberOfTrainingSamplesTouse\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"More Samples Asked For Than Present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNumberOfTrainingSamplesTouse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: More Samples Asked For Than Present"]}]},{"cell_type":"code","source":["train_nonaug_dataset, target_nonaug_train, test_nonaug_dataset, target_nonaug_test = buildTrainTestDatasets(False, None, None, 500, None)\n","train_nonaug_dataset = tf.squeeze(train_nonaug_dataset)\n","test_nonaug_dataset = tf.squeeze(test_nonaug_dataset)\n","target_nonaug_train = tf.squeeze(target_nonaug_train)\n","target_nonaug_test = tf.squeeze(target_nonaug_test)"],"metadata":{"id":"aJaj2By5R9yc","executionInfo":{"status":"aborted","timestamp":1706768044629,"user_tz":-420,"elapsed":21,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_aug = tf.data.Dataset.from_tensor_slices((train_aug_dataset, target_aug_train))\n","train_non_aug = tf.data.Dataset.from_tensor_slices((train_nonaug_dataset, target_nonaug_train))\n","test_aug = tf.data.Dataset.from_tensor_slices((test_aug_dataset, target_aug_test))\n","test_non_aug = tf.data.Dataset.from_tensor_slices((test_nonaug_dataset, target_nonaug_test))"],"metadata":{"id":"HpcuFauoRonn","executionInfo":{"status":"aborted","timestamp":1706768044631,"user_tz":-420,"elapsed":23,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for example, label in train_aug.take(1):\n","  print('text: ', example.numpy())\n","  print('label: ', label.numpy())"],"metadata":{"id":"9tt4_o6nDjKg","executionInfo":{"status":"aborted","timestamp":1706768044635,"user_tz":-420,"elapsed":26,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for example, label in train_aug.take(10):\n","  print('text: ', example.numpy())\n","  print('label: ', label.numpy())"],"metadata":{"id":"rhha0eFCJSMK","executionInfo":{"status":"aborted","timestamp":1706768044636,"user_tz":-420,"elapsed":26,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_aug, train_non_aug, test_aug, test_non_aug"],"metadata":{"id":"3wkN7_fUIkgo","executionInfo":{"status":"aborted","timestamp":1706768044636,"user_tz":-420,"elapsed":26,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for example, label in train_aug.take(1):\n","  print('text: ', example.numpy())\n","  print('label: ', label.numpy())"],"metadata":{"id":"jBHyN24V9GoO","executionInfo":{"status":"aborted","timestamp":1706768044637,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BUFFER_SIZE = 10000\n","BATCH_SIZE = 64"],"metadata":{"id":"C91enohDBOXj","executionInfo":{"status":"aborted","timestamp":1706768044638,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_aug = train_aug.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","test_aug = test_aug.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","train_non_aug = train_non_aug.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","test_non_aug = test_non_aug.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"9P0lYpBKBO8z","executionInfo":{"status":"aborted","timestamp":1706768044639,"user_tz":-420,"elapsed":28,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_aug.element_spec"],"metadata":{"id":"8H7SIij7Bb7V","executionInfo":{"status":"aborted","timestamp":1706768044639,"user_tz":-420,"elapsed":28,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for example, label in train_aug.take(1):\n","  print('texts: ', example.numpy()[:3])\n","  print()\n","  print('labels: ', label.numpy()[:3])"],"metadata":{"id":"38xXXT1gBe1M","executionInfo":{"status":"aborted","timestamp":1706768044639,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RNN Model\n","\n","Paper Uses -\n","The architecture used in this paper is as follows: input layer, bi-directional hidden layer with 64 LSTM cells, dropout layer with p=0.5, bi-directional layer of 32 LSTM cells, dropout layer with p=0.5, dense layer of 20 hidden units with ReLU activation, softmax output layer. We initialize this network with random normal weights and train against the categorical crossentropy loss function with the adam optimizer. We use early stopping with a patience of 3 epochs.\n","\n","Reference for Encoder and some Helper Functions: [Tensorflow Text Classification by RNN Tutorial](https://www.tensorflow.org/text/tutorials/text_classification_rnn)\n","\n"],"metadata":{"id":"JPXHX5UV78ui"}},{"cell_type":"code","source":["VOCAB_SIZE = 5000\n","encoder_aug = tf.keras.layers.TextVectorization(\n","    max_tokens=VOCAB_SIZE)\n","encoder_aug.adapt(train_aug.map(lambda text, label: text))\n","\n","vocab_aug = np.array(encoder_aug.get_vocabulary())\n","\n","VOCAB_SIZE = 5000\n","encoder_nonaug = tf.keras.layers.TextVectorization(\n","    max_tokens=VOCAB_SIZE)\n","encoder_nonaug.adapt(train_non_aug.map(lambda text, label: text))\n","\n","vocab_nonaug = np.array(encoder_nonaug.get_vocabulary())"],"metadata":{"id":"Td-Iboc0BNIU","executionInfo":{"status":"aborted","timestamp":1706768044639,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_example = encoder_aug(example)[:3].numpy()\n","encoded_example\n","\n","for n in range(3):\n","  print(\"Original: \", example[n].numpy())\n","  print(\"Round-trip: \", \" \".join(vocab_aug[encoded_example[n]]))\n","  print()"],"metadata":{"id":"pOTl3S9DljnX","executionInfo":{"status":"aborted","timestamp":1706768044639,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_aug = tf.keras.Sequential([\n","    encoder_aug,\n","    tf.keras.layers.Embedding(len(encoder_aug.get_vocabulary()), 64, mask_zero=True),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(20, activation='relu'),\n","    tf.keras.layers.Dense(1, kernel_initializer='normal', activation='sigmoid')\n","])\n","model_aug.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])\n","\n","model_nonaug = tf.keras.Sequential([\n","    encoder_nonaug,\n","    tf.keras.layers.Embedding(len(encoder_nonaug.get_vocabulary()), 64, mask_zero=True),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(20, activation='relu'),\n","    tf.keras.layers.Dense(1, kernel_initializer='normal', activation='sigmoid')\n","])\n","model_nonaug.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"bx_aazpwWe1f","executionInfo":{"status":"aborted","timestamp":1706768044639,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n","\n","history_aug = model_aug.fit(\n","      train_aug,\n","      epochs=50,\n","      callbacks=callbacks,\n","      validation_data=test_aug,\n","      validation_steps=5\n",")\n","\n","history_non_aug = model_nonaug.fit(\n","      train_non_aug,\n","      epochs=50,\n","      callbacks=callbacks,\n","      validation_data=test_non_aug,\n","      validation_steps=5\n",")"],"metadata":{"id":"Bn39t9aqrp6o","executionInfo":{"status":"aborted","timestamp":1706768044640,"user_tz":-420,"elapsed":27,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_aug_loss, test_aug_acc = model_aug.evaluate(test_aug)\n","\n","print('Test Augmented Loss:', test_aug_loss)\n","print('Test Augmented Accuracy:', test_aug_acc)\n","\n","test_non_aug_loss, test_non_aug_acc = model_nonaug.evaluate(test_non_aug)\n","\n","print('Test Non Augmented Loss:', test_non_aug_loss)\n","print('Test Non Augmented Accuracy:', test_non_aug_acc)"],"metadata":{"id":"qjBusEOGuHK3","executionInfo":{"status":"aborted","timestamp":1706768044640,"user_tz":-420,"elapsed":25,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Augmented Data Training\n","plt.figure(figsize=(16, 8))\n","plt.subplot(1, 2, 1)\n","plot_graphs(history_aug, 'accuracy')\n","plt.ylim(None, 1)\n","plt.subplot(1, 2, 2)\n","plot_graphs(history_aug, 'loss')\n","plt.ylim(0, None)"],"metadata":{"id":"MrDDpT2NF7UJ","executionInfo":{"status":"aborted","timestamp":1706768044640,"user_tz":-420,"elapsed":25,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Non Augmented Data Training\n","plt.figure(figsize=(16, 8))\n","plt.title(\"Non Augmented Data Training\")\n","plt.subplot(1, 2, 1)\n","plot_graphs(history_non_aug, 'accuracy')\n","plt.ylim(None, 1)\n","plt.subplot(1, 2, 2)\n","plot_graphs(history_non_aug, 'loss')\n","plt.ylim(0, None)"],"metadata":{"id":"sN_pYcqLY4fu","executionInfo":{"status":"aborted","timestamp":1706768044640,"user_tz":-420,"elapsed":24,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aots4DHNAEWI","executionInfo":{"status":"aborted","timestamp":1706768044640,"user_tz":-420,"elapsed":24,"user":{"displayName":"Putri Rizqiyah","userId":"16341400528146937175"}}},"execution_count":null,"outputs":[]}]}